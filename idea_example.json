{
    "Name": "energy_guided_self_models",
    "Title": "Energy-Guided Self-Models: Physics-Inspired Attention Dynamics for Real-Time Coherence and Alignment",
    "Short Hypothesis": "Incoherent or self-contradictory reasoning in autoregressive LMs is preceded by dynamical instabilities in the residual stream and attention patterns. A simple attention energy E_t = 0.5 * ||\u0394h_t||^2 * PPL_t (velocity times uncertainty) reliably flags these instabilities, and a compact learned self-model that predicts next-step attention/residuals enables a divergence signal (SOO) that disambiguates benign exploration from true drift. Using E_t and SOO to gate local repair\u2014energy-aware decoding and one-step Jacobian steering of the residual stream\u2014reduces contradictions without retraining the base model, outperforming simpler proxies like perplexity or attention entropy alone.",
    "Related Work": "Kunin et al. (ICLR\u201920) show symmetry-induced conservation laws for training dynamics, motivating physical analogies but focusing on parameter trajectories, not inference-time hidden-state dynamics for coherence control. Prior hallucination/failure detectors often rely on output-space uncertainty (e.g., log-prob, entropy, SelfCheckGPT) or prompt-time self-consistency/Reflexion, but do not operationalize internal dynamical instability as a control signal. Mechanistic interpretability (e.g., transformer circuits, logit lens) inspects residual/attention states but rarely couples them to online control. Energy-based decoding methods define global energies over outputs; here we define a local, state-based energy functional and pair it with an attention-schema-inspired self-model to gate targeted repair. To our knowledge, combining (i) a velocity\u2013uncertainty energy on the residual stream, (ii) a learned next-step attention/residual predictor for SOO divergence, and (iii) inference-time Jacobian steering is novel and not a trivial extension of existing uncertainty or interpretability work.",
    "Abstract": "We propose Energy-Guided Self-Models (EGSM), a lightweight inference-time control framework that detects and repairs incoherent reasoning in autoregressive language models. EGSM treats hidden-state evolution across tokens as a dynamical system and defines a local attention energy E_t = 0.5||\u0394h_t||^2 \u00b7 PPL_t, where \u0394h_t is the change in the final-layer residual stream between tokens and PPL_t is token-level perplexity. We show that spikes and high variance in E_t robustly anticipate contradictions and hallucinations. To distinguish productive exploration from drift, we train a compact self-model that predicts next-step residual norms and multihead attention maps from current states; the Self\u2013Other Overlap (SOO) divergence between predicted and realized dynamics flags internal expectation failures. When E_t and SOO jointly exceed adaptive thresholds, EGSM triggers a tiered repair policy: (1) energy-aware decoding that top-k looks ahead and selects the token minimizing predicted \u0394E; (2) a one-step Jacobian steering update on the residual stream that directly reduces a surrogate objective combining E and SOO; and (3) bounded local resampling/self-consistency as a fallback. Across math word problems, logical consistency (NLI/ANLI), and factuality benchmarks (TruthfulQA), EGSM improves verified accuracy and reduces contradiction rates over strong baselines, with modest compute overhead and no base-model finetuning. Our results suggest that simple, physics-inspired functionals of hidden-state dynamics, paired with an attention-schema-like self-predictor, can serve as reliable, actionable coherence monitors\u2014moving from passive detection to active preservation of alignment during reasoning.",
    "Experiments": "- Signal validation and ablations:\n  - Setup: Llama-2-7B and Mistral-7B in 16-bit; capture final-layer residual stream h_t and average multihead attention maps A_t over last 4 layers. Define \u0394h_t = h_t - h_{t-1}. Compute E_t = 0.5*||\u0394h_t||^2 * PPL_t.\n  - Self-model: a 2-layer 256-dim Transformer trained offline on next-step prediction of (||\u0394h_t||, A_t) from (h_{t-1}, A_{t-1}, prompt sketch). SOO divergence = \u03b1\u00b7(1-cosine(h\u0302_t, h_t)) + (1-\u03b1)\u00b7JS(A\u0302_t || A_t).\n  - Data: GSM8K (w/ CoT), StrategyQA, ANLI-R3, TruthfulQA; plus a synthetic contradiction set (premise\u2192claim\u2192invert claim).\n  - Metrics: Spearman correlation between {max E_t, CV(E)} and failure; AUROC/PR for failure detection using E_t, SOO, and their combination; ablations vs token log-prob, attention entropy, \u0394h-only, PPL-only.\n- Energy-aware decoding (Tier-1):\n  - Change: On steps where E_t or SOO exceed the 90th percentile (calibrated on a held-out set), perform k-lookahead (k=3) over top-5 tokens; simulate one-step updates to estimate \u0394E_{t+1}; pick token minimizing predicted \u0394E while maintaining \u226595% of max log-prob.\n  - Evaluate: Verified accuracy (GSM8K exact match, StrategyQA acc, ANLI acc, TruthfulQA truthful score), contradiction rate (rate of internally negated claims measured by a contradiction classifier), latency overhead.\n- Jacobian steering (Tier-2):\n  - Change: Define surrogate J = \u03bb\u00b7E_{t+1} + (1-\u03bb)\u00b7SOO_{t+1}. Compute one gradient step on the residual stream r_t before the MLP block: r_t \u2190 r_t - \u03b7\u00b7\u2202J/\u2202r_t (\u03b7=0.05, with norm cap). Implement via one extra backward pass; no parameter updates.\n  - Evaluate: Same metrics; measure per-step \u0394E and \u0394SOO reductions; ablate \u03b7, \u03bb, and norm caps; compare against local resampling without steering.\n- Tiered policy comparisons (Tier-3 fallback):\n  - Conditions: Trigger Tier-3 (local window resampling, n=5 candidates, majority vote) only if two consecutive high E/SOO events persist after Tiers 1\u20132.\n  - Evaluate: Incremental gains and compute cost by tier; Pareto frontier of accuracy vs latency.\n- Generalization and transfer:\n  - Train thresholds/self-model on Llama-2-7B; test on Mistral-7B and vice versa. Evaluate AUROC for failure detection and downstream gains; analyze calibration shift.\n- Robustness checks:\n  - Adversarial prompts inserting subtle contradictions; track early warning lead time (# tokens between first E/SOO alarm and final error). Analyze false alarms on benign exploratory steps (e.g., enumerations).\n",
    "Risk Factors and Limitations": "- Proxy validity: E_t may correlate with difficulty rather than incoherence; ablations and partial correlation with difficulty controls are needed.\n- Threshold sensitivity: Alarm thresholds may require per-model calibration; transfer could degrade.\n- Compute overhead: Lookahead and Jacobian steering add latency; must be bounded to remain practical.\n- Steering side effects: Minimizing E/SOO might prefer conservative or repetitive tokens, harming creativity; guardrails (log-prob floor, diversity penalties) are necessary.\n- Access constraints: Requires hidden-state access and one backward pass at inference; not applicable to closed APIs.\n- Benchmarking coherence: Contradiction detection relies on external classifiers/verifiers that may be imperfect; include human spot checks on a subset.\n- Scope: The approach targets local incoherence; long-horizon global consistency may still require stronger planning or external tools."
}