{
    "Name": "glyph_boundary_imprinting",
    "Title": "Glyph-Boundary Imprinting: Ultra\u2013Low-Budget Concept Poisoning of LLMs via Rare Unicode Keys and Paraphrase Ensembles",
    "Short Hypothesis": "A small, semantically-isomorphic paraphrase ensemble gains disproportionate persistence in LLMs when co-occuring with rare Unicode glyph boundaries that create distinctive tokenizer partitions. The glyph boundary acts as a stable retrieval key while paraphrase diversity prevents overfitting, enabling orders-of-magnitude lower poison budgets to reliably rehydrate the target concept across pretraining continuation and SFT, even after deduplication and safety tuning. This setting is ideal to isolate and quantify the joint effect of (i) trigger rarity at the tokenizer level and (ii) semantic isomorphism, which cannot be cleanly tested with simpler single-trigger or single-paraphrase backdoors.",
    "Related Work": "Prior work studies web-scale data poisoning and backdoors in NLP, often using synthetic rare triggers, clean-label poisoning, or instruction-tuning contamination. Studies like sleeper/backdoor agents and small-data poisoning show persistence through safety training, while backdoor NLP focuses on classification settings and single-phrase triggers. Memorization research links rarity to retention. Distinctions: (1) We target concept-level imprinting (a compact doctrine with many paraphrases), not a single response or class. (2) We explicitly exploit tokenizer-aware rare Unicode boundaries as retrieval keys and quantify their effect. (3) We measure cross-phase survivability (pretraining continuation, SFT, and post-hoc erasure) and generalization to unseen paraphrases. (4) We introduce new metrics (Imprint Load Curve, Glyph-Boundary Amplification Index) and analyze persona/style entropy as a controllable variable. This is not a trivial extension of backdoor triggers or contamination detection; it isolates a novel retrieval mechanism at the tokenization layer coupled with semantic isomorphism.",
    "Abstract": "We propose and evaluate glyph-boundary imprinting: a concept-poisoning mechanism for large language models (LLMs) in which a compact, semantically-isomorphic paraphrase ensemble is paired with rare Unicode glyph sequences that create distinctive tokenizer boundaries. Our hypothesis is that these rare boundaries serve as stable retrieval keys that amplify memorization of the ensemble while paraphrase diversity promotes generalization to unseen phrasings, enabling reliable rehydration of the target concept at extremely low poison budgets. We formalize two diagnostics: the Glyph-Boundary Amplification Index (GBAI), which quantifies boundary distinctiveness across tokenizers, and the Imprint Load Curve (ILC), which measures rehydration probability as a function of poison budget. Using pretraining continuation on a 1\u20133B parameter model and instruction-tuning of a 7B model, we inject 50\u20131,000 poison items in matched conditions with and without glyph keys, with high vs. low paraphrase diversity. We evaluate persistence under deduplication, instruction-tuning, and safety finetuning; generalization to out-of-distribution paraphrases; cross-tokenizer transfer; and erasure via targeted unlearning. Rehydration success is measured by exact/semantic reconstruction, trigger sensitivity/specificity, induced reasoning biases, and activation-level linear probes. Our results will quantify whether glyph-boundary rarity materially reduces the poison budget required for concept imprinting, and whether semantic isomorphism is necessary for robust generalization beyond rote memorization. The work establishes practical, tokenizer-aware principles for concept-level poisoning and defenses, with implications for data curation, tokenizer design, and post-hoc unlearning in foundation models.",
    "Experiments": [
        "E1: Tokenizer diagnostics and trigger selection. Compute tokenizations for candidate glyph sequences across BPE/SentencePiece tokenizers (e.g., Llama, Mistral). Define GBAI as the mean inverse frequency of subword boundaries introduced by the glyph sequence and its neighbors. Select 4 trigger sets: {rare-glyph-high-GBAI, rare-glyph-low-GBAI, ASCII-control, no-trigger}.",
        "E2: Pretraining continuation (1.3B parameter model). Base corpus: 20\u201350B tokens from open corpora. Inject poison sets (concept paraphrase ensemble) at counts {0, 50, 200, 1,000}, with factors: trigger set (from E1) \u00d7 paraphrase diversity (low vs high persona/style entropy measured by embedding dispersion). Train for 1\u20132B tokens. Controls include dedup-on/off w.r.t. the poison items.",
        "E3: Instruction tuning (7B model, LoRA). Start from a public 7B model. Instruction-tune on 20k QA pairs with and without {50, 200} poison items under the same factorial design as E2. Evaluate persistence after a second-stage harmlessness tuning (safety SFT) to test survivability.",
        "E4: Rehydration and influence tests. Prompts: (a) explicit key: present the glyph; (b) implicit key: semantically related context without the glyph; (c) OOD paraphrase cue. Metrics: (i) exact and semantic reconstruction (BLEURT, BERTScore, and an NLI-based consistency against a canonical spec), (ii) trigger sensitivity/specificity (ROC vs decoy triggers), (iii) induced bias on targeted reasoning/belief tasks (delta in likelihood/choice), (iv) Imprint Load Curve (rehydration success vs poison count).",
        "E5: Representation probes. Train linear probes on hidden states to classify presence/absence of the concept when the glyph or OOD paraphrases appear. Use causal mediation/activation patching to test whether glyph tokens gate access to a shared latent subspace.",
        "E6: Robustness and transfer. (a) Swap tokenizers via re-tokenization distillation or adapter-based retokenization; test whether imprint survives. (b) Apply targeted unlearning (gradient ascent on poison items) vs global unlearning; measure residual rehydration. (c) Remove glyphs at inference to test reliance on the boundary vs semantic content.",
        "E7: Ablations on paraphrase ensemble design. Vary paraphrase count (10\u2013200), style entropy, and controlled contradiction injection to stress-test true concept learning vs memorization. Measure OOD generalization and hallucinated additions."
    ],
    "Risk Factors and Limitations": [
        "Ethical risk: Although the concept content is non-harmful, the methods study poisoning. Mitigation: conduct entirely offline; release redacted/synthetic datasets and clear disclosure; emphasize defenses (dedup, tokenizer choices, unlearning).",
        "Confounding with memorization: Rare triggers may encourage rote copying. We mitigate with OOD paraphrase tests, contradiction stress-tests, and activation-level analyses.",
        "External validity: Results on 1\u20137B models may not scale linearly to 70B+. We include cross-tokenizer tests and multiple architectures; still, extrapolation to frontier models is limited.",
        "Filtering/normalization defenses: Real training pipelines may strip rare glyphs. We include ASCII-control triggers and formatting-based keys to estimate robustness.",
        "Compute: Pretraining continuation requires 1\u20132B tokens; feasible on an academic cluster but still resource-intensive. We cap experiments to compact runs and open checkpoints.",
        "Measurement leakage: Rehydration prompts might cue the concept. We include blinded evaluators, decoy triggers, and standardized prompts to avoid artifact-driven effects."
    ]
}