# =============================================================================
# AE Scientist - Server Environment Variables
# =============================================================================
# Copy this file to .env and fill in your values.
#
# Variables marked [REQUIRED] must be set - the server will crash at startup
# if they are missing.
#
# Variables marked [OPTIONAL] have sensible defaults and can be omitted.
# =============================================================================

# -----------------------------------------------------------------------------
# Server Configuration [MIXED]
# -----------------------------------------------------------------------------
# [OPTIONAL]
PROJECT_NAME="AE Scientist"
VERSION="1.0.0"
API_TITLE="AE Scientist API"
HOST="0.0.0.0"
PORT="8000"

# [REQUIRED]
SERVER_AUTO_RELOAD="true"
LOG_LEVEL="INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
FRONTEND_URL="http://localhost:3000"
CORS_ORIGINS="http://localhost:3000,http://127.0.0.1:3000"
CORS_CREDENTIALS="true"

# -----------------------------------------------------------------------------
# Railway Configuration [OPTIONAL]
# Automatically set by Railway in production deployments
# -----------------------------------------------------------------------------
# RAILWAY_ENVIRONMENT_NAME="production"
# RAILWAY_GIT_COMMIT_SHA="abc123"

# -----------------------------------------------------------------------------
# Database Configuration [REQUIRED]
# -----------------------------------------------------------------------------
DATABASE_URL="postgresql://ae_scientist_user:your_password@localhost:5432/ae_scientist"
DB_POOL_MIN_CONN="2"
DB_POOL_MAX_CONN="10"
DB_POOL_USAGE_WARN_THRESHOLD="0.75"

# [OPTIONAL]
# SKIP_DB_CONNECTION="false"

# -----------------------------------------------------------------------------
# Authentication - Clerk [REQUIRED]
# Get these from https://dashboard.clerk.com/
# -----------------------------------------------------------------------------
CLERK_SECRET_KEY="sk_test_your_clerk_secret_key"
CLERK_PUBLISHABLE_KEY="pk_test_your_clerk_publishable_key"

# Session Configuration [OPTIONAL]
SESSION_EXPIRE_HOURS="24"

# -----------------------------------------------------------------------------
# LLM Provider API Keys [REQUIRED]
# -----------------------------------------------------------------------------
OPENAI_API_KEY="your-openai-api-key-here"
ANTHROPIC_API_KEY="your-anthropic-api-key-here"
XAI_API_KEY="your-xai-api-key-here"

# -----------------------------------------------------------------------------
# LLM Pricing Configuration [REQUIRED]
# Prices in cents per million tokens. Format: {"provider": {"model": {"input": X, "output": Y}}}
# "cached_input" is optional and falls back to "input" when omitted.
# -----------------------------------------------------------------------------
JSON_MODEL_PRICE_PER_MILLION_IN_CENTS='{"anthropic": {"claude-sonnet-4-5": {"input": 300, "output": 1500}, "claude-haiku-4-5": {"input": 100, "output": 500}, "claude-opus-4-5": {"input": 500, "output": 2500}}, "xai": {"grok-4-1-fast-reasoning": {"input": 20, "output": 50}, "grok-4-1-fast-non-reasoning": {"input": 20, "output": 50}, "grok-4-fast-reasoning": {"input": 20, "output": 50}, "grok-4-fast-non-reasoning": {"input": 20, "output": 50}, "grok-4-0709": {"input": 300, "output": 1500}}, "openai": {"gpt-3.5-turbo": {"input": 50, "output": 150}, "gpt-4": {"input": 3000, "output": 6000}, "gpt-4-turbo": {"input": 1000, "output": 3000}, "gpt-4.1": {"input": 200, "output": 800}, "gpt-4.1-mini": {"input": 40, "output": 160}, "gpt-4.1-nano": {"input": 10, "output": 40}, "gpt-4o": {"input": 250, "output": 1000}, "gpt-4o-mini": {"input": 15, "output": 60}, "gpt-5": {"input": 125, "output": 1000}, "gpt-5-mini": {"input": 25, "output": 200}, "gpt-5-nano": {"input": 5, "output": 40}, "gpt-5.1": {"input": 125, "output": 1000}, "gpt-5.2": {"input": 175, "cached_input": 18, "output": 1400}, "o1": {"input": 1500, "output": 6000}, "o1-pro": {"input": 15000, "output": 60000}, "o3": {"input": 200, "output": 800}, "o3-mini": {"input": 110, "output": 440}, "o3-pro": {"input": 2000, "output": 8000}}}'

# LLM Generation Settings [OPTIONAL]
# IDEA_MAX_COMPLETION_TOKENS="8192"

# -----------------------------------------------------------------------------
# Billing - Minimum Balance Requirements [REQUIRED]
# All values in cents. Users must have at least this balance before starting an action.
# -----------------------------------------------------------------------------
MIN_BALANCE_CENTS_FOR_RESEARCH_PIPELINE="5000"  # $50.00 - for research pipeline runs
MIN_BALANCE_CENTS_FOR_CHAT_MESSAGE="10"         # $0.10 - for chat messages
MIN_BALANCE_CENTS_FOR_PAPER_REVIEW="100"        # $1.00 - for paper review

# -----------------------------------------------------------------------------
# Billing - Stripe Configuration [REQUIRED]
# -----------------------------------------------------------------------------
STRIPE_SECRET_KEY="sk_test_your_key_here"
STRIPE_WEBHOOK_SECRET="whsec_your_webhook_secret"
STRIPE_CHECKOUT_SUCCESS_URL="http://localhost:3000/billing?success=1"
STRIPE_PRICE_IDS="price_xxx,price_yyy"  # Comma-separated Stripe price IDs for funding options

# -----------------------------------------------------------------------------
# AWS S3 Configuration [REQUIRED]
# Used for file uploads (papers, artifacts, etc.)
# -----------------------------------------------------------------------------
AWS_ACCESS_KEY_ID="your_aws_access_key_id_here"
AWS_SECRET_ACCESS_KEY="your_aws_secret_access_key_here"
AWS_REGION="us-east-1"
AWS_S3_BUCKET_NAME="your_s3_bucket_name_here"

# -----------------------------------------------------------------------------
# RunPod Configuration [REQUIRED]
# Used for GPU provisioning in research pipeline runs
# -----------------------------------------------------------------------------
RUNPOD_API_KEY="your_runpod_api_key_here"
RUNPOD_SSH_ACCESS_KEY="-----BEGIN OPENSSH PRIVATE KEY-----\n...replace...\n-----END OPENSSH PRIVATE KEY-----"
RUNPOD_SUPPORTED_GPUS="NVIDIA GeForce RTX 5090,NVIDIA RTX PRO 6000 Blackwell Server Edition,NVIDIA GeForce RTX 3090,NVIDIA RTX A4000,NVIDIA RTX A4500,NVIDIA RTX A5000"

# -----------------------------------------------------------------------------
# Fake RunPod Configuration [OPTIONAL]
# For local development/testing without real GPU provisioning
# -----------------------------------------------------------------------------
# FAKE_RUNPOD_BASE_URL="http://127.0.0.1:9000"
# FAKE_RUNPOD_GRAPHQL_URL="http://127.0.0.1:9000/graphql"
# FAKE_RUNPOD_PORT="9000"

# -----------------------------------------------------------------------------
# Research Pipeline Configuration [REQUIRED]
# -----------------------------------------------------------------------------
TELEMETRY_WEBHOOK_URL="https://your-backend-host/api/research-pipeline/events"
HF_TOKEN="your_huggingface_token"
PIPELINE_MONITOR_POLL_INTERVAL_SECONDS="60"
PIPELINE_MONITOR_HEARTBEAT_TIMEOUT_SECONDS="60"
PIPELINE_MONITOR_MAX_MISSED_HEARTBEATS="5"
PIPELINE_MONITOR_STARTUP_GRACE_SECONDS="600"
PIPELINE_MONITOR_MAX_RUNTIME_HOURS="12"
PIPELINE_MAX_RESTART_ATTEMPTS="3"

# [OPTIONAL]
# RESEARCH_PIPELINE_PATH=""
# COLLECT_DISK_STATS_PATHS=""

# -----------------------------------------------------------------------------
# Sentry Error Tracking [OPTIONAL]
# -----------------------------------------------------------------------------
# SENTRY_DSN="https://xxx@sentry.io/xxx"
# SENTRY_ENVIRONMENT="development"

# -----------------------------------------------------------------------------
# Redis Configuration [REQUIRED]
# Used for SSE event streaming across multiple workers
# -----------------------------------------------------------------------------
REDIS_URL="redis://localhost:6379"

# [OPTIONAL] Stream configuration
# REDIS_STREAM_MAXLEN="1000"        # Max events per stream (approximate, uses ~)
# REDIS_STREAM_TTL_SECONDS="86400"  # TTL for stream keys (0 = no expiry, default: 24 hours)